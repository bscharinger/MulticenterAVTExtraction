{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_tensorflow"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "colab": {
   "name": "main (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "gather": {
     "logged": 1635980540292
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "id": "vo77MIgCU3bW"
   },
   "source": [
    "from __future__ import division\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import time\n",
    "import helper_funcs\n",
    "from data_gen import CTA\n",
    "from tensorflow.python.client import device_lib\n",
    "from Networks import model_unet_2\n",
    "from helper_funcs import dice_coef_loss\n",
    "import skimage\n",
    "import patchify"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Config paths and mixed precision for reduced memory\n",
    "Load model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ECBhMooU3bY",
    "outputId": "9e2cc2b4-34f9-4eca-9437-20698b5638a7"
   },
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "training_dir = \"./training_data/train_cyl_grey_im/\"\n",
    "label_dir = \"./training_data/train_cyl_grey_la/\"\n",
    "data_list =glob('{}/*.nrrd'.format(training_dir))\n",
    "label_list=glob('{}/*.nrrd'.format(label_dir))\n",
    "\n",
    "policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "img_size = (512, 512, 40)\n",
    "model = model_unet_2.get_model(img_size)\n",
    "a=model.summary(line_length=150)\n",
    "\n"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "(None, 512, 512, 40, 1)\n",
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             [(None, 512, 512, 40, 1)]        0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                                  (None, 512, 512, 40, 16)         448               input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization (BatchNormalization)         (None, 512, 512, 40, 16)         64                conv3d[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation (Activation)                          (None, 512, 512, 40, 16)         0                 batch_normalization[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)                                (None, 512, 512, 40, 16)         6928              activation[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNormalization)       (None, 512, 512, 40, 16)         64                conv3d_1[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_1 (Activation)                        (None, 512, 512, 40, 16)         0                 batch_normalization_1[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)                     (None, 256, 256, 20, 16)         0                 activation_1[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)                                (None, 256, 256, 20, 16)         6928              max_pooling3d[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNormalization)       (None, 256, 256, 20, 16)         64                conv3d_2[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_2 (Activation)                        (None, 256, 256, 20, 16)         0                 batch_normalization_2[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)                                (None, 256, 256, 20, 16)         6928              activation_2[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNormalization)       (None, 256, 256, 20, 16)         64                conv3d_3[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_3 (Activation)                        (None, 256, 256, 20, 16)         0                 batch_normalization_3[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)                   (None, 128, 128, 10, 16)         0                 activation_3[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)                                (None, 128, 128, 10, 16)         6928              max_pooling3d_1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_4[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_4 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_4[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)                                (None, 128, 128, 10, 16)         6928              activation_4[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_5[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_5 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_5[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)                   (None, 64, 64, 5, 16)            0                 activation_5[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)                                (None, 64, 64, 5, 16)            6928              max_pooling3d_2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNormalization)       (None, 64, 64, 5, 16)            64                conv3d_6[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_6 (Activation)                        (None, 64, 64, 5, 16)            0                 batch_normalization_6[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)                                (None, 64, 64, 5, 16)            6928              activation_6[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNormalization)       (None, 64, 64, 5, 16)            64                conv3d_7[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_7 (Activation)                        (None, 64, 64, 5, 16)            0                 batch_normalization_7[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)                     (None, 128, 128, 10, 16)         0                 activation_7[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate (Concatenate)                        (None, 128, 128, 10, 32)         0                 up_sampling3d[0][0]                               \n",
      "                                                                                                    activation_5[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)                                (None, 128, 128, 10, 16)         13840             concatenate[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_8[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_8 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_8[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)                                (None, 128, 128, 10, 16)         6928              activation_8[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_9[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_9 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_9[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)                   (None, 256, 256, 20, 16)         0                 activation_9[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)                      (None, 256, 256, 20, 32)         0                 up_sampling3d_1[0][0]                             \n",
      "                                                                                                    activation_3[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)                               (None, 256, 256, 20, 16)         13840             concatenate_1[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNormalization)      (None, 256, 256, 20, 16)         64                conv3d_10[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_10 (Activation)                       (None, 256, 256, 20, 16)         0                 batch_normalization_10[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)                               (None, 256, 256, 20, 16)         6928              activation_10[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNormalization)      (None, 256, 256, 20, 16)         64                conv3d_11[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_11 (Activation)                       (None, 256, 256, 20, 16)         0                 batch_normalization_11[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)                   (None, 512, 512, 40, 16)         0                 activation_11[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)                      (None, 512, 512, 40, 32)         0                 up_sampling3d_2[0][0]                             \n",
      "                                                                                                    activation_1[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)                               (None, 512, 512, 40, 16)         13840             concatenate_2[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNormalization)      (None, 512, 512, 40, 16)         64                conv3d_12[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_12 (Activation)                       (None, 512, 512, 40, 16)         0                 batch_normalization_12[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)                               (None, 512, 512, 40, 16)         6928              activation_12[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNormalization)      (None, 512, 512, 40, 16)         64                conv3d_13[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_13 (Activation)                       (None, 512, 512, 40, 16)         0                 batch_normalization_13[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)                               (None, 512, 512, 40, 1)          17                activation_13[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_14 (Activation)                       (None, 512, 512, 40, 1)          0                 conv3d_14[0][0]                                   \n",
      "======================================================================================================================================================\n",
      "Total params: 112,161\n",
      "Trainable params: 111,713\n",
      "Non-trainable params: 448\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data into training and validation set\n",
    "Initialise sequence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "gather": {
     "logged": 1633709498961
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true,
    "id": "UJWnfZpZU3bb"
   },
   "source": [
    "val_samples = int(np.floor(len(data_list)*0.2))\n",
    "random.Random(7331).shuffle(data_list)\n",
    "random.Random(7331).shuffle(label_list)\n",
    "\n",
    "train_img_paths = data_list[:-val_samples]\n",
    "train_lab_paths = label_list[:-val_samples]\n",
    "\n",
    "val_img_paths = data_list[-val_samples:]\n",
    "val_lab_paths = label_list[-val_samples:]\n",
    "\n",
    "train_gen = CTA(train_img_paths, train_lab_paths,1)\n",
    "valid_gen = CTA(val_img_paths, val_lab_paths,1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enable dynamic memory allocation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ],
   "metadata": {
    "id": "0zcH4AMACF9-"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile model\n",
    "Add callback to check loss inside of epoch\n",
    "train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxFe6hDqU3bc",
    "outputId": "376caa2e-5f02-4a0f-dc64-f01c4ba267f8"
   },
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=[dice_coef_loss], metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "epochs = 200\n",
    "\n",
    "class BatchHistories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "batch_loss = BatchHistories()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\"unet2_toy_train_z40_grey.h5\", verbose=1, save_best_only=True),\n",
    "    batch_loss\n",
    "]\n",
    "start = time.time()\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "806/806 [==============================] - 1018s 1s/step - loss: 0.0517 - binary_crossentropy: 0.3114 - val_loss: 0.0180 - val_binary_crossentropy: 0.1759\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01799, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 2/200\n",
      "806/806 [==============================] - 929s 1s/step - loss: 0.0087 - binary_crossentropy: 0.0989 - val_loss: 0.0015 - val_binary_crossentropy: 0.0380\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01799 to 0.00148, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 3/200\n",
      "806/806 [==============================] - 926s 1s/step - loss: 8.8603e-04 - binary_crossentropy: 0.0286 - val_loss: 6.1031e-04 - val_binary_crossentropy: 0.0236\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00148 to 0.00061, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 4/200\n",
      "806/806 [==============================] - 917s 1s/step - loss: 4.5929e-04 - binary_crossentropy: 0.0201 - val_loss: 3.6143e-04 - val_binary_crossentropy: 0.0177\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00061 to 0.00036, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 5/200\n",
      "806/806 [==============================] - 919s 1s/step - loss: 2.9756e-04 - binary_crossentropy: 0.0157 - val_loss: 2.4403e-04 - val_binary_crossentropy: 0.0142\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00036 to 0.00024, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 6/200\n",
      "806/806 [==============================] - 936s 1s/step - loss: 2.1585e-04 - binary_crossentropy: 0.0131 - val_loss: 1.8539e-04 - val_binary_crossentropy: 0.0121\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00024 to 0.00019, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 7/200\n",
      "806/806 [==============================] - 923s 1s/step - loss: 1.6804e-04 - binary_crossentropy: 0.0112 - val_loss: 1.4564e-04 - val_binary_crossentropy: 0.0104\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00019 to 0.00015, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 8/200\n",
      "806/806 [==============================] - 936s 1s/step - loss: 1.3770e-04 - binary_crossentropy: 0.0099 - val_loss: 1.2105e-04 - val_binary_crossentropy: 0.0093\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00015 to 0.00012, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 9/200\n",
      "806/806 [==============================] - 946s 1s/step - loss: 1.1776e-04 - binary_crossentropy: 0.0089 - val_loss: 1.0498e-04 - val_binary_crossentropy: 0.0084\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00012 to 0.00010, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 10/200\n",
      "806/806 [==============================] - 933s 1s/step - loss: 1.0360e-04 - binary_crossentropy: 0.0082 - val_loss: 9.2181e-05 - val_binary_crossentropy: 0.0077\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00010 to 0.00009, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 11/200\n",
      "806/806 [==============================] - 931s 1s/step - loss: 9.3195e-05 - binary_crossentropy: 0.0076 - val_loss: 8.5040e-05 - val_binary_crossentropy: 0.0073\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00009 to 0.00009, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 12/200\n",
      "806/806 [==============================] - 1147s 1s/step - loss: 8.4996e-05 - binary_crossentropy: 0.0071 - val_loss: 7.7253e-05 - val_binary_crossentropy: 0.0068\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00009 to 0.00008, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 13/200\n",
      "806/806 [==============================] - 1521s 2s/step - loss: 7.8413e-05 - binary_crossentropy: 0.0067 - val_loss: 6.9975e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00008 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 14/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.5205e-05 - binary_crossentropy: 0.0065 - val_loss: 7.0057e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00007\n",
      "Epoch 15/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.4557e-05 - binary_crossentropy: 0.0064 - val_loss: 6.9587e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 16/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.4087e-05 - binary_crossentropy: 0.0064 - val_loss: 6.9165e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 17/200\n",
      "806/806 [==============================] - 1541s 2s/step - loss: 7.3623e-05 - binary_crossentropy: 0.0064 - val_loss: 6.8748e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 18/200\n",
      "806/806 [==============================] - 1520s 2s/step - loss: 7.3153e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8202e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 19/200\n",
      "806/806 [==============================] - 1516s 2s/step - loss: 7.2897e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8222e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00007\n",
      "Epoch 20/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2872e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8237e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00007\n",
      "Epoch 21/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2826e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8113e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 22/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2795e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8170e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00007\n",
      "Epoch 23/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2773e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8118e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00007\n",
      "Epoch 24/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2763e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8190e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00007\n",
      "Epoch 25/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2763e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8110e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 26/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8181e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00007\n",
      "Epoch 27/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8105e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 28/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8070e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 29/200\n",
      "806/806 [==============================] - 1557s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8116e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00007\n",
      "Epoch 30/200\n",
      "806/806 [==============================] - 1514s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8149e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00007\n",
      "Epoch 31/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8158e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00007\n",
      "Epoch 32/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8214e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00007\n",
      "Epoch 33/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8165e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00007\n",
      "Epoch 34/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8206e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00007\n",
      "Epoch 35/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8172e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00007\n",
      "Epoch 36/200\n",
      "806/806 [==============================] - 1536s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8110e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00007\n",
      "Epoch 37/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8187e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00007\n",
      "Epoch 38/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8149e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00007\n",
      "Epoch 00038: early stopping\n",
      "Training time:  51403.73484945297\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_pretrained_cyl_z40_new\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Model_pretrained_cyl_z40_new')\n",
    "model.save('Model_pretrained_cyl_z40_new.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Dice loss')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApJUlEQVR4nO3deXjU5bn/8fedPSGABIMLCQUX9LCG/biAC3VptSKKC9oKta6tWttLe6x1O6indflVj7UtasXt2IJiS6noweN2wOpRlkYKKmUxSpAqawAhZLt/f8x3hkkyCQNkMmPm87quXDPf/Z7vlcyd53m+z/OYuyMiItJURrIDEBGR1KQEISIiMSlBiIhITEoQIiISkxKEiIjElJXsANrKgQce6L179052GCIiXymLFi3a4O7FsbZ1mATRu3dvFi5cmOwwRES+Uszsk5a2qYpJRERiUoIQEZGYlCBERCSmDtMGISJQW1tLZWUl1dXVyQ5FUkxeXh4lJSVkZ2fHfYwShEgHUllZSefOnenduzdmluxwJEW4Oxs3bqSyspI+ffrEfZyqmEQ6kOrqarp3767kII2YGd27d9/rkqUShEgHo+QgsezL74USRFUlvH43bFyV7EhERFKKEsSX62HevbB+ebIjEfnKO+mkk5g7d26jdQ8++CBXX311i8eceOKJkU6u3/zmN9myZUuzfe644w7uv//+Vq89a9YsPvjgg8jybbfdxquvvroX0cf25ptv0rVrV4YMGcJRRx3FmDFjePHFFyPbp06dytNPP73f1+nduzcbNmzY7/O0JTVS53QOvdZsT24cIh3AxIkTmT59Oqeddlpk3fTp07n33nvjOv6ll17a52vPmjWLM888k379+gEwZcqUfT5XU6NHj44khfLycs4++2zy8/MZO3YsV111VZtdJ9WoBJFbGHrdtS25cYh0ABMmTGDOnDnU1NQAUFFRwWeffcbo0aO5+uqrGT58OP379+f222+PeXz0f9F33303ffv25fjjj2f58t0l/Mcee4wRI0YwePBgzj33XHbs2MHbb7/N7NmzufHGGykrK2PVqlVMnjyZmTNnAvDaa68xZMgQBg4cyKWXXsquXbsi17v99tsZOnQoAwcO5KOPPtrjZywrK+O2227j4YcfBhqXblauXMnXv/51Bg8ezNChQ1m1KlR1fd999zFixAgGDRrU4mePpaKigpNPPplBgwYxduxYPv30UwCef/55BgwYwODBgxkzZgwAy5YtY+TIkZSVlTFo0CBWrFgR93VaohJETpAgVIKQDubf/7KMDz7b2qbn7HdoF27/Vv8WtxcVFTFy5Ehefvllxo0bx/Tp0zn//PMxM+6++26Kioqor69n7NixLFmyhEGDBsU8z6JFi5g+fTrl5eXU1dUxdOhQhg0bBsA555zD5ZdfDsAtt9zC448/zrXXXstZZ53FmWeeyYQJExqdq7q6msmTJ/Paa6/Rt29fLrnkEn77299y/fXXA3DggQeyePFifvOb33D//ffzu9/9bo/3YejQodx3333N1l988cXcdNNNjB8/nurqahoaGnjllVdYsWIF7733Hu7OWWedxbx58yJf7K259tprmTRpEpMmTWLatGlcd911zJo1iylTpjB37lx69uwZqZKbOnUqP/zhD7n44oupqamhvr5+j+ffk4SWIMzsdDNbbmYrzeymGNtzzWxGsP1dM+sdrO9tZjvNrDz4mZqwILMLAIOaLxN2CZF0Eq5mglD10sSJEwF47rnnGDp0KEOGDGHZsmWN2guamj9/PuPHj6egoIAuXbpw1llnRbYtXbqU0aNHM3DgQJ599lmWLVvWajzLly+nT58+9O3bF4BJkyYxb968yPZzzjkHgGHDhlFRURHXZ3T3Zuu2bdvG2rVrGT9+PBDqmFZQUMArr7zCK6+8wpAhQxg6dCgfffRR3P/dv/POO1x00UUAfOc73+Gtt94C4LjjjmPy5Mk89thjkURwzDHH8B//8R/cc889fPLJJ+Tn58d1jdYkrARhZpnAr4FTgEpggZnNdvfo34rvAZvd/QgzuxC4B7gg2LbK3csSFV9ERgbkdIJdKkFIx9Laf/qJNG7cOH70ox+xePFiduzYwbBhw/j444+5//77WbBgAd26dWPy5Mn73Nt78uTJzJo1i8GDB/Pkk0/y5ptv7le8ubm5AGRmZlJXVxfXMX/729/4l3/5l7j2dXd++tOfcuWVV+5zjE1NnTqVd999lzlz5jBs2DAWLVrERRddxKhRo5gzZw7f/OY3eeSRRzj55JP36zqJLEGMBFa6+2p3rwGmA+Oa7DMOeCp4PxMYa8l4iDunEGrUBiHSFgoLCznppJO49NJLI6WHrVu30qlTJ7p27crnn3/Oyy+/3Oo5xowZw6xZs9i5cyfbtm3jL3/5S2Tbtm3bOOSQQ6itreXZZ5+NrO/cuTPbtjX/Oz7qqKOoqKhg5cqVADzzzDOccMIJ+/z5lixZwp133skPfvCDRus7d+5MSUkJs2bNAmDXrl3s2LGD0047jWnTprF9e+if0LVr1/LFF1/Eda1jjz02Uhp79tlnGT16NACrVq1i1KhRTJkyheLiYtasWcPq1as57LDDuO666xg3bhxLlizZ588Ylsg2iJ7AmqjlSmBUS/u4e52ZVQHdg219zOxvwFbgFnef3/QCZnYFcAVAr1699j3S3EKVIETa0MSJExk/fnzky23w4MEMGTKEo48+mtLSUo477rhWjx86dCgXXHABgwcPpkePHowYMSKy7c4772TUqFEUFxczatSoSFK48MILufzyy3nooYcijdMQqup54oknOO+886irq2PEiBF7/eTR/PnzGTJkCDt27KBHjx489NBDjB07ttl+zzzzDFdeeSW33XYb2dnZPP/885x66ql8+OGHHHPMMUAogf7Xf/0XPXr0aHb8oEGDyMgI/d9+/vnn86tf/Yrvfve73HfffRQXF/PEE08AcOONN7JixQrcnbFjxzJ48GDuuecennnmGbKzszn44IO5+eab9+ozxmKx6tLagplNAE5398uC5e8Ao9z9mqh9lgb7VAbLqwglkW1AobtvNLNhwCygv7u32OI2fPhw3+cJgx45AQp7wMXP79vxIiniww8/jLvqQ9JPrN8PM1vk7sNj7Z/IKqa1QGnUckmwLuY+ZpYFdAU2uvsud98I4O6LgFVA34RFmttZjdQiIk0kMkEsAI40sz5mlgNcCMxuss9sYFLwfgLwuru7mRUHjdyY2WHAkcDqhEWa00n9IEREmkhYG0TQpnANMBfIBKa5+zIzmwIsdPfZwOPAM2a2EthEKIkAjAGmmFkt0ABc5e6bEhVrqJFabRAiItES2lHO3V8CXmqy7rao99XAeTGOewF4IZGxNaJGahGRZjTUBgQlCLVBiIhEU4KAUIKo/RIaGpIdiYhIylCCgN0D9qkdQmS/bNy4kbKyMsrKyjj44IPp2bNnZDk8gF9LFi5cyHXXXbdX1+vduzcDBw5k4MCB9OvXj1tuuSXSQ/uzzz5rNi7TvohnqPGOSoP1QeMB+/K6JDcWka+w7t27U15eDoS+WAsLC7nhhhsi2+vq6sjKiv21M3z4cIYPj/k4fqveeOMNDjzwQLZv384VV1zBlVdeyVNPPcWhhx7aqMOc7D2VICDUDwLUUC2SAJMnT+aqq65i1KhR/OQnP+G9997jmGOOYciQIRx77LGRobzffPNNzjzzTCCUXC699FJOPPFEDjvsMB566KE9XqewsJCpU6cya9YsNm3aREVFBQMGDACgvr6eG264gQEDBjBo0CB+9atfAaFRY0844QSGDRvGaaedxrp16+L6TO7OjTfeyIABAxg4cCAzZswAYN26dYwZM4aysjIGDBjA/Pnzqa+vZ/LkyZF9H3jggb2+h8miEgRoyG/pmF6+Cf7597Y958ED4Ru/2OvDKisrefvtt8nMzGTr1q3Mnz+frKwsXn31VW6++WZeeKH5Q4sfffQRb7zxBtu2beOoo47i6quvJjs7u9XrdOnShT59+rBixQoOOuigyPpHH32UiooKysvLycrKYtOmTdTW1nLttdfy5z//meLiYmbMmMHPfvYzpk2btsfP88c//pHy8nLef/99NmzYwIgRIxgzZgy///3vOe200/jZz35GfX09O3bsoLy8nLVr17J06VKAmDPmpSolCAh1lAMlCJEEOe+888jMzASgqqqKSZMmsWLFCsyM2tramMecccYZ5ObmkpubS48ePfj8888pKSnZ47ViDR/06quvctVVV0Wqt4qKili6dClLly7llFNOAUKljEMOOSSuz/PWW28xceJEMjMzOeiggzjhhBNYsGABI0aM4NJLL6W2tpazzz6bsrIyDjvsMFavXs21117LGWecwamnnhrXNVKBEgREzSqnBCEdyD78p58onTp1iry/9dZbOemkk/jTn/5ERUUFJ554YsxjwsNwQ/xDcW/bto2Kigr69u1LVVVVq/u6O/379+edd96J70PEYcyYMcybN485c+YwefJkfvzjH3PJJZfw/vvvM3fuXKZOncpzzz0XVyklFagNAjQvtUg7qqqqomfPngA8+eSTbXbe7du38/3vf5+zzz6bbt26Ndp2yimn8Mgjj0SSzKZNmzjqqKNYv359JEHU1tbucfKhsNGjRzNjxgzq6+tZv3498+bNY+TIkXzyySccdNBBXH755Vx22WUsXryYDRs20NDQwLnnnstdd93F4sWL2+wzJ5pKEKB5qUXa0U9+8hMmTZrEXXfdxRlnnLHf5zvppJNwdxoaGhg/fjy33nprs30uu+wy/vGPfzBo0CCys7O5/PLLueaaa5g5cybXXXcdVVVV1NXVcf3119O/f/OJlu666y4efPDByPKaNWt45513GDx4MGbGvffey8EHH8xTTz3FfffdR3Z2NoWFhTz99NOsXbuW7373uzQE/ax+/vOf7/dnbi8JG+67ve3XcN+7tsHPS+CUO+G4vXsOWySVaLhvaU0qDff91ZGtRmoRkaaUICCYl1oD9omIRFOCCNO81NJBdJRqY2lb+/J7oQQRlqsRXeWrLy8vj40bNypJSCPuzsaNG8nLy9ur4/QUU1hOJ1UxyVdeSUkJlZWVrF+/PtmhSIrJy8uLq6NhNCWIsJzOaqSWr7zs7Gz69OmT7DCkg1AVU1huofpBiIhEUYII07zUIiKNKEGE5XRSI7WISBQliLDczmqkFhGJogQRpnmpRUQaUYII07zUIiKNKEGEaVY5EZFGlCDCIglCDdUiIqAEsZvmhBARaUQJIkxVTCIijShBhGleahGRRpQgwtQGISLSSEIThJmdbmbLzWylmd0UY3uumc0Itr9rZr2bbO9lZtvN7IZExglEJQi1QYiIQAIThJllAr8GvgH0AyaaWb8mu30P2OzuRwAPAPc02f5L4OVExdiIqphERBpJZAliJLDS3Ve7ew0wHRjXZJ9xwFPB+5nAWDMzADM7G/gYWJbAGHfTvNQiIo0kMkH0BNZELVcG62Lu4+51QBXQ3cwKgX8D/r21C5jZFWa20MwW7vcEKZqXWkSkkVRtpL4DeMDdW/22dvdH3X24uw8vLi7e/6vmdFIJQkQkkMgZ5dYCpVHLJcG6WPtUmlkW0BXYCIwCJpjZvcABQIOZVbv7wwmMV3NCiIhESWSCWAAcaWZ9CCWCC4GLmuwzG5gEvANMAF730Gzro8M7mNkdwPaEJwcIZpVTghARgQQmCHevM7NrgLlAJjDN3ZeZ2RRgobvPBh4HnjGzlcAmQkkkeTQvtYhIRCJLELj7S8BLTdbdFvW+GjhvD+e4IyHBxZJbCFs/a7fLiYikslRtpE4OTTsqIhKhBBFNjdQiIhFKENE0L7WISIQSRDTNSy0iEqEEES0nGG6jVu0QIiJKENE0YJ+ISIQSRLSczqFXNVSLiChBNKJ5qUVEIpQgomleahGRCCWIaOFGanWWExFRgmgkN2iDUCO1iIgSRCOal1pEJEIJIpoecxURiVCCiKZ5qUVEIpQgomVkhJKEGqlFRJQgmsktVD8IERGUIJrTkN8iIoASRHOal1pEBFCCaE4lCBERQAmiOSUIERFACaI5VTGJiABKEM2pBCEiAihBNJejEoSICChBNJerealFREAJornwgH2al1pE0pwSRFMasE9EBFCCaE7zUouIAHuZIMysm5kNSlQwKSE8q5zGYxKRNLfHBGFmb5pZFzMrAhYDj5nZLxMfWpKEq5g0oquIpLl4ShBd3X0rcA7wtLuPAr4ez8nN7HQzW25mK83sphjbc81sRrD9XTPrHawfaWblwc/7ZjZ+Lz7T/onMKqcqJhFJb/EkiCwzOwQ4H3gx3hObWSbwa+AbQD9gopn1a7Lb94DN7n4E8ABwT7B+KTDc3cuA04FHzCwr3mvvF81LLSICxJcgpgBzgZXuvsDMDgNWxHHcyOCY1e5eA0wHxjXZZxzwVPB+JjDWzMzdd7h7XbA+D/A4rtc2wm0QmpdaRNLcHhOEuz/v7oPc/fvB8mp3PzeOc/cE1kQtVwbrYu4TJIQqoDuAmY0ys2XA34GrohJGhJldYWYLzWzh+vXr4wgpDjl6zFVEBOJrpL43aKTONrPXzGy9mX070YG5+7vu3h8YAfzUzPJi7POouw939+HFxcVtc+EcNVKLiEB8VUynBo3UZwIVwBHAjXEctxYojVouCdbF3CdoY+gKbIzewd0/BLYDA+K45v6LzEutEoSIpLe4GqmD1zOA5929Ks5zLwCONLM+ZpYDXAjMbrLPbGBS8H4C8Lq7e3BMFoCZfQ04mlByah+al1pEhHieDHrRzD4CdgJXm1kxUL2ng9y9zsyuIdTAnQlMc/dlZjYFWOjus4HHgWfMbCWwiVASATgeuMnMaoEG4PvuvmFvP9w+y1EJQkTE3Pf8gFDQSa7K3evNrADo4u7/THh0e2H48OG+cOHCtjnZ1NHQ5VC4aEbbnE9EJEWZ2SJ3Hx5r2x5LEGaWDXwbGGNmAP8LTG3TCFNNbmc9xSQiaS+eNojfAsOA3wQ/Q4N1HVdOofpBiEjai6cNYoS7D45aft3M3k9UQCkhtxA2qgQhIuktnhJEvZkdHl4IelLXJy6kFKBGahGRuEoQNwJvmNlqwICvAd9NaFTJltNZHeVEJO3tMUG4+2tmdiRwVLBqubvvSmxYSZZbGCpBNDSEOs6JiKShFhOEmZ3TwqYjzAx3/2OCYkq+6Hmpw6O7ioikmdZKEN9qZZsDHThBhGeV264EISJpq8UE4e4du52hNbmal1pERBXssWhWORERJYiYcjUnhIiIEkQsKkGIiMQ1YVCBmd1qZo8Fy0ea2ZmJDy2JNKuciEhcJYgngF3AMcHyWuCuhEWUCnJVghARiSdBHO7u9wK1AO6+g1CP6o5LVUwiInEliBozyyfU94FgXKaO3ZM6uh+EiEiaimcsptuB/wZKzexZ4DhgciKDSrqMTMguUAlCRNJaPGMx/Y+ZLQb+lVDV0g/bdfrPZMnRvNQikt7ieYppPFDn7nPc/UWgzszOTnhkyZZbqBFdRSStxdMGcbu7V4UX3H0LoWqnji2nUFVMIpLW4kkQsfaJp+3iq03zUotImosnQSw0s1+a2eHBzy+BRYkOLOlyOmleahFJa/EkiGuBGmBG8LML+EEig0oJOYUqQYhIWovnKaYvgZvaIZbUokZqEUlzrc0o96C7X29mfyHoJBfN3c9KaGTJltNZjdQiktZaK0E8E7ze3x6BpJycTpqXWkTSWmszyi0KXv/XzIqD9+vbK7Cky9W81CKS3lr919jM7jCzDcBy4B9mtt7Mbmuf0JIsMmCf2iFEJD21mCDM7MeExl0a4e5F7t4NGAUcZ2Y/aq8AkyZcatCTTCKSplorQXwHmOjuH4dXuPtq4NvAJYkOLOkiJQj1hRCR9NRagsiONShf0A6RHc/Jzex0M1tuZivNrNmjsmaWa2Yzgu3vmlnvYP0pZrbIzP4evJ4c5+dpOxryW0TSXGsJomYftwFgZpnAr4FvAP2AiWbWr8lu3wM2u/sRwAPAPcH6DcC33H0gMIndT1S1H80qJyJprrXHXAeb2dYY6w3Ii+PcI4GVQbUUZjYdGAd8ELXPOOCO4P1M4GEzM3f/W9Q+y4B8M8t19/abqCgnaINQI7WIpKnWHnPN3M9z9wTWRC1XEmrkjrmPu9eZWRXQnVAJIuxcYHGs5GBmVwBXAPTq1Ws/w20iXILQnBAikqZSugeYmfUnVO10Zazt7v6ouw939+HFxcVte/FwG4SqmEQkTSUyQawFSqOWS4J1MfcxsyygK7AxWC4B/gRc4u6rEhhnbOGnmNRILSJpKpEJYgFwpJn1MbMc4EJgdpN9ZhNqhAaYALzu7m5mBwBzgJvc/a8JjLFlmpdaRNJcwhKEu9cB1wBzgQ+B59x9mZlNMbPwQH+PA93NbCXwY3aPGnsNcARwm5mVBz89EhVrizSrnIiksYTODOfuLwEvNVl3W9T7auC8GMfdBdyVyNjikqs5IUQkfaV0I3V7WL9tF39471PWVe1svjE8oquISBpK+wTxz6pqfvrHv/P+mi3NN+ZoXmoRSV9pnyB6FRUAsGZTjBJEbqHGYhKRtJX2CaJrQTad87JYs3lH8405mnZURNJX2icICJUiPt0UK0F0UhWTiKQtJQigtFsBa2IliFzNSy0i6UsJAigtyqdy804aGrzxhnA/iIaG5AQmIpJEShCEqph21TWwfnuT8QAj81LHKF2IiHRwShBASeRJpiaJIEdzQohI+lKCINQGATR/kkkD9olIGlOCAEq65QPw6cYmfSFyNS+1iKQvJQggLzuTg7rkqgQhIhJFCSIQ81HXSAlCneVEJP0oQQR6FcVIEJF5qVWCEJH0owQRKCkqYN3Wamrqovo8hKcd1bzUIpKGlCACpd3ycYe1W6IaqnP1mKuIpC8liECvWH0h1EgtImlMCSJQWhSjL4TmpRaRNKYEETioSx45mRnNR3XVrHIikqaUIAKZGUbPbvlUNp04KEfzUotIelKCiFLSLb95Z7ncQpUgRCQtKUFEiTlxUE5ndZQTkbSkBBGltKiALTtq2VZdu3tlbqH6QYhIWlKCiBIZ1TW6HUKN1CKSppQgooT7QnzatC+EGqlFJA0pQUQpLQoN+10Z3VCtealFJE0pQUTpmp9N59ys5r2pa77UvNQiknaUIKKYGaVNn2TK6QS45qUWkbSjBNFEaVE+azZrwD4RkYQmCDM73cyWm9lKM7spxvZcM5sRbH/XzHoH67ub2Rtmtt3MHk5kjE2FJw5y99CK8JwQaqgWkTSTsARhZpnAr4FvAP2AiWbWr8lu3wM2u/sRwAPAPcH6auBW4IZExdeSXt0L2FXXwPptu0IrNC+1iKSpRJYgRgIr3X21u9cA04FxTfYZBzwVvJ8JjDUzc/cv3f0tQomiXUX6QoSfZMrRtKMikp4SmSB6AmuiliuDdTH3cfc6oAroHu8FzOwKM1toZgvXr1+/n+GGRIb9DneW05wQIpKmvtKN1O7+qLsPd/fhxcXFbXLOkm6hvhCRJ5nUSC0iaSqRCWItUBq1XBKsi7mPmWUBXYGNCYxpj/KyM+nROXd3X4hICUJtECKSXhKZIBYAR5pZHzPLAS4EZjfZZzYwKXg/AXjdI48PJU+vooLdbRC5aoMQkfSUlagTu3udmV0DzAUygWnuvszMpgAL3X028DjwjJmtBDYRSiIAmFkF0AXIMbOzgVPd/YNExRuttKiA9z7eFFrI7hR6VQlCRNJMwhIEgLu/BLzUZN1tUe+rgfNaOLZ3ImNrTWm3fP5cvpOaugZysrLggK/BP5ckKxwRkaT4SjdSJ0ppUQENDp9tCZ5kOvxk+Hge1Ne2fqCISAeiBBFD5FHXcDvEEWNDTzGteS+JUYmItC8liBia9YXoMwYsE1a9lsSoRETalxJEDAd3ySM703b3hcjrCiUjYNXryQ1MRKQdKUHEkJlh9Dwgf3cVE4SqmT4rhy+T2k1DRKTdKEG0oLSogMroeSEOHws4rH4jaTGJiLQnJYgWNJs46NAyyO+maiYRSRtKEC0o7VbA5h21bN9VF1qRkQmHnRhKEMnv7C0iknBKEC3oFXmSqUk107Z18EW7dOgWEUkqJYgWlBY1GdUVQh3mQNVMIpIWlCBaEJk4KDpBdO0JxUfDSvWHEJGOTwmiBQcUZNM5N4vKzTsbbzh8LHzyNtTujH2giEgHoQTRAjOjpOmTTBCqZqrfBZ/8NTmBiYi0EyWIVpR2y29cxQTwtWMhMxdWqh1CRDo2JYhWhCcOajSHUU5BKEmooVpEOjgliFaUFhVQXdvA+u27Gm84/GRY/yFUNZ1BVUSk41CCaEX4UdfIqK5hR4wNvaoUISIdmBJEK8Kd5So3N2mH6NEPCg9WghCRDk0JohUlQV+ITzc2SRBmoWqm1W9AQ30SIhMRSTwliFbkZWdS3Dm38bDfYUeMhZ2bYV15u8clItIelCD2oFdRQfM2CAgN3IfpcVcR6bCUIPagtFt+885yAJ0OhEMGaxpSEemwlCD2oLSogHVVO6mtb2i+8YixsOY9qN7a/oGJiCSYEsQelBYV0OCwbkt1842HnwxeDx/Pa//AREQSTAliD8KjusasZioZCTmFqmYSkQ5JCWIPenVvJUFk5UCfMeoPISIdkhLEHhzcJY8DCrK588UP+LeZS1hSuaXxDoefDJsrYOOqZIQnIpIwShB7kJlhPHflMYwrO5TZ73/GWQ//lW/96i2mv/cpO2rqNMuciHRY1mik0q+w4cOH+8KFCxN6ja3Vtcz621qe/b9PWf75NjrnZjF+aE9uWXURObVb4WvHwSFlcGhZ6LWwOKHxiIjsLzNb5O7DY25LZIIws9OB/wQygd+5+y+abM8FngaGARuBC9y9Itj2U+B7QD1wnbvPbe1a7ZEgwtydRZ9s5tl3P2XO39cxqqGcSfl/pT+rOaR+9wiv1QUHU9djEDmlQ8k5pH+o70R+ERQUQX43yMxul3hFRFqSlARhZpnAP4BTgEpgATDR3T+I2uf7wCB3v8rMLgTGu/sFZtYP+AMwEjgUeBXo6+4tDnzUngki2uYva3hhcSXvV1bx2ZadVG3eQPH25fSzjxmY8TED7WP62D/JsOb3eUdGJ3ZmdqU6uys1OV2pz8ynISsfz8rHs/Lw7HzILsCyC7DsPCw7F8vMJSMrG8vMJiM7l4ysHDKzssnIyiUjM5uMrCwyMrOwjCwsI5PMrCwsM5vMzCwyMjOxjEwygh/LyAh+ssAywDJD40xZRvBj7X4/RaR9tZYgshJ43ZHASndfHQQxHRgHfBC1zzjgjuD9TOBhM7Ng/XR33wV8bGYrg/O9k8B490m3TjlcNvqwRuvq6hv4fNsuPtuyk6VbdvLGho3Ub1xJxs5NZFRvJqt6Czm1W8ir3UJBXRWdarbSefsX5FFDPrvItxpyqaGAXWRZjA567ajBjQYMN8MJ/4CTEfXeGv0QtS7We2z3OoPIOYjeJ1gfvUyT9fvK2yTxKXlK6lh74PGM+v5jbX7eRCaInsCaqOVKYFRL+7h7nZlVAd2D9f/X5NieTS9gZlcAVwD06tWrzQLfX1mZGfQ8IJ+eB+QHa3oCg1o9xt2prXdq6huoqWtgR10DW+oaqKmppnbXDuqqv6Shrob62l14fQ0NtTXU19XgdbU01Nfgdbvw+jq8oR4a6nBvwOrr8Ia60IizDXW414M3YA314B7q5OcNmDeANwTLoa/r8Hp3x9yD7Q1Evs7dgYbg2zr4ug9vdxpt273/7mWiS64eTjXh7btfw8ft/jrev/Rg+51eaBy7SApoOKBPQs6byASRcO7+KPAohKqYkhzOfjEzcrKMnKwMyI3eUgAUJSkqEUlniXzMdS1QGrVcEqyLuY+ZZQFdCTVWx3OsiIgkUCITxALgSDPrY2Y5wIXA7Cb7zAYmBe8nAK97qNV8NnChmeWaWR/gSOC9BMYqIiJNJKyKKWhTuAaYS+gx12nuvszMpgAL3X028DjwTNAIvYlQEiHY7zlCDdp1wA9ae4JJRETanjrKiYiksdYec9VQGyIiEpMShIiIxKQEISIiMSlBiIhITB2mkdrM1gOf7McpDgQ2tFE4iaIY24ZibBuKsW0kO8avuXvMoac7TILYX2a2sKWW/FShGNuGYmwbirFtpHKMqmISEZGYlCBERCQmJYjdHk12AHFQjG1DMbYNxdg2UjZGtUGIiEhMKkGIiEhMShAiIhJT2icIMzvdzJab2UozuynZ8cRiZhVm9nczKzezlBmR0MymmdkXZrY0al2Rmf2Pma0IXrulYIx3mNna4H6Wm9k3kxxjqZm9YWYfmNkyM/thsD5l7mUrMabMvTSzPDN7z8zeD2L892B9HzN7N/gbnxFMP5BqMT5pZh9H3ceyZMUYLa3bIMwsE/gHcAqhaU0XABPd/YNWD2xnZlYBDHf3lOrwY2ZjgO3A0+4+IFh3L7DJ3X8RJNxu7v5vKRbjHcB2d78/WXFFM7NDgEPcfbGZdQYWAWcDk0mRe9lKjOeTIvcymM++k7tvN7Ns4C3gh8CPgT+6+3Qzmwq87+6/TbEYrwJedPeZyYirJeleghgJrHT31e5eA0wHxiU5pq8Md59HaB6PaOOAp4L3TxH6EkmaFmJMKe6+zt0XB++3AR8Smsg8Ze5lKzGmDA/ZHixmBz8OnAyEv3iTfR9bijElpXuC6AmsiVquJMV+6QMOvGJmi8zsimQHswcHufu64P0/gYOSGUwrrjGzJUEVVFKrwaKZWW9gCPAuKXovm8QIKXQvzSzTzMqBL4D/AVYBW9y9Ltgl6X/jTWN09/B9vDu4jw+YWW7LZ2g/6Z4gviqOd/ehwDeAHwTVJikvmD42Ff87+i1wOFAGrAP+X1KjCZhZIfACcL27b43elir3MkaMKXUv3b3e3csIzWM/Ejg6mfHE0jRGMxsA/JRQrCOAIiBp1bLR0j1BrAVKo5ZLgnUpxd3XBq9fAH8i9Iufqj4P6qvD9dZfJDmeZtz98+CPtAF4jBS4n0F99AvAs+7+x2B1St3LWDGm4r0EcPctwBvAMcABZhaeXjll/sajYjw9qMJzd98FPEGK3Md0TxALgCODpxxyCM2JPTvJMTViZp2CRkHMrBNwKrC09aOSajYwKXg/CfhzEmOJKfylGxhPku9n0HD5OPChu/8yalPK3MuWYkyle2lmxWZ2QPA+n9DDJx8S+hKeEOyW7PsYK8aPov4RMEJtJCnxN57WTzEBBI/lPQhkAtPc/e7kRtSYmR1GqNQAkAX8PlViNLM/ACcSGq74c+B2YBbwHNCL0PDr57t70hqJW4jxREJVIg5UAFdG1fW3OzM7HpgP/B1oCFbfTKiOPyXuZSsxTiRF7qWZDSLUCJ1J6J/f59x9SvA3NJ1Q1c3fgG8H/6mnUoyvA8WAAeXAVVGN2UmT9glCRERiS/cqJhERaYEShIiIxKQEISIiMSlBiIhITEoQIiISkxKESMDMtgevvc3sojY+981Nlt9uy/OLJIIShEhzvYG9ShBRPXVb0ihBuPuxexmTSLtTghBp7hfA6GBc/h8Fg6vdZ2YLgsHUrgQwsxPNbL6ZzQY+CNbNCgZVXBYeWNHMfgHkB+d7NlgXLq1YcO6lFprz44Koc79pZjPN7CMzezboZYuZ/cJC8zIsMbOkD7MtHdee/usRSUc3ATe4+5kAwRd9lbuPCEbZ/KuZvRLsOxQY4O4fB8uXuvumYBiFBWb2grvfZGbXBAO0NXUOoZ7Igwn19l5gZvOCbUOA/sBnwF+B48zsQ0JDWhzt7h4etkEkEVSCENmzU4FLgiGa3wW6A0cG296LSg4A15nZ+8D/ERoI8khadzzwh2DAu8+B/yU0omf43JXBQHjlhKq+qoBq4HEzOwfYsZ+fTaRFShAie2bAte5eFvz0cfdwCeLLyE5mJwJfB45x98GExv3J24/rRo8XVA9kBfMajCQ0Ac6ZwH/vx/lFWqUEIdLcNqBz1PJc4OpguGvMrG8wsm5TXYHN7r7DzI4G/jVqW234+CbmAxcE7RzFwBjgvZYCC+Zj6OruLwE/IlQ1JZIQaoMQaW4JUB9UFT0J/Ceh6p3FQUPxemJPW/nfwFVBO8FyQtVMYY8CS8xssbtfHLX+T4TmLHif0IioP3H3fwYJJpbOwJ/NLI9QyebH+/QJReKg0VxFRCQmVTGJiEhMShAiIhKTEoSIiMSkBCEiIjEpQYiISExKECIiEpMShIiIxPT/ASGnj5XVEyIwAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['val_loss'], label='Validation Dice Loss')\n",
    "plt.plot(history.history['loss'], label='Train Dice Loss')\n",
    "#plt.plot(batch_loss.losses)\n",
    "plt.legend()\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Dice loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transfer learning begin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "training_dir = \"./training_data/train_patch_z40_dnep_im\"\n",
    "label_dir = \"./training_data/train_patch_z40_dnep_la\"\n",
    "data_list =glob('{}/*.nrrd'.format(training_dir))\n",
    "label_list=glob('{}/*.nrrd'.format(label_dir))\n",
    "val_samples = int(np.floor(len(data_list)*0.2))\n",
    "random.Random(7331).shuffle(data_list)\n",
    "random.Random(7331).shuffle(label_list)\n",
    "\n",
    "train_img_paths = data_list[:-val_samples]\n",
    "train_lab_paths = label_list[:-val_samples]\n",
    "\n",
    "val_img_paths = data_list[-val_samples:]\n",
    "val_lab_paths = label_list[-val_samples:]\n",
    "\n",
    "train_gen = CTA(train_img_paths, train_lab_paths,1)\n",
    "valid_gen = CTA(val_img_paths, val_lab_paths,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model for transferlearning\n",
    "Freeze down path\n",
    "compile model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model_pret = keras.models.load_model('unet2_toy_train_z40_grey.h5', compile=False)\n",
    "for layer in model_pret.layers[:23]:\n",
    "\tlayer.trainable = False\n",
    "model_pret.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=[dice_coef_loss], metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transfer learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "372/372 [==============================] - 414s 1s/step - loss: 0.0025 - binary_crossentropy: 0.0313 - val_loss: 0.0019 - val_binary_crossentropy: 0.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00195, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 2/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0020 - binary_crossentropy: 0.0272 - val_loss: 0.0019 - val_binary_crossentropy: 0.0249\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00195 to 0.00186, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 3/200\n",
      "372/372 [==============================] - 386s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0254 - val_loss: 0.0018 - val_binary_crossentropy: 0.0237\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00186 to 0.00182, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 4/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0242 - val_loss: 0.0018 - val_binary_crossentropy: 0.0226\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00182 to 0.00179, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 5/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0235 - val_loss: 0.0018 - val_binary_crossentropy: 0.0218\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00179 to 0.00178, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 6/200\n",
      "372/372 [==============================] - 387s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0227 - val_loss: 0.0018 - val_binary_crossentropy: 0.0212\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00178 to 0.00176, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 7/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0221 - val_loss: 0.0018 - val_binary_crossentropy: 0.0209\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00176 to 0.00175, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 8/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0218 - val_loss: 0.0017 - val_binary_crossentropy: 0.0205\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00175 to 0.00175, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 9/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0214 - val_loss: 0.0017 - val_binary_crossentropy: 0.0201\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00175 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 10/200\n",
      "372/372 [==============================] - 392s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0211 - val_loss: 0.0017 - val_binary_crossentropy: 0.0199\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 11/200\n",
      "372/372 [==============================] - 379s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0208 - val_loss: 0.0017 - val_binary_crossentropy: 0.0198\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 12/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0206 - val_loss: 0.0018 - val_binary_crossentropy: 0.0196\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00174\n",
      "Epoch 13/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0203 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00174\n",
      "Epoch 14/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0202 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00174\n",
      "Epoch 15/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00174\n",
      "Epoch 16/200\n",
      "372/372 [==============================] - 487s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00174\n",
      "Epoch 17/200\n",
      "372/372 [==============================] - 585s 2s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00174\n",
      "Epoch 18/200\n",
      "372/372 [==============================] - 550s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00174\n",
      "Epoch 19/200\n",
      "372/372 [==============================] - 499s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00174\n",
      "Epoch 20/200\n",
      "372/372 [==============================] - 501s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00174\n",
      "Epoch 21/200\n",
      "372/372 [==============================] - 468s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00174\n",
      "Epoch 22/200\n",
      "372/372 [==============================] - 464s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00174\n",
      "Epoch 23/200\n",
      "372/372 [==============================] - 451s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00174\n",
      "Epoch 24/200\n",
      "372/372 [==============================] - 448s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00174\n",
      "Epoch 25/200\n",
      "372/372 [==============================] - 450s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 26/200\n",
      "372/372 [==============================] - 448s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00174\n",
      "Epoch 27/200\n",
      "372/372 [==============================] - 450s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00174\n",
      "Epoch 28/200\n",
      "372/372 [==============================] - 440s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00174\n",
      "Epoch 29/200\n",
      "372/372 [==============================] - 433s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00174\n",
      "Epoch 30/200\n",
      "372/372 [==============================] - 416s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00174\n",
      "Epoch 31/200\n",
      "372/372 [==============================] - 407s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00174\n",
      "Epoch 32/200\n",
      "372/372 [==============================] - 404s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00174\n",
      "Epoch 33/200\n",
      "372/372 [==============================] - 398s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00174\n",
      "Epoch 34/200\n",
      "372/372 [==============================] - 396s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00174\n",
      "Epoch 35/200\n",
      "372/372 [==============================] - 394s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00174\n",
      "Epoch 36/200\n",
      "372/372 [==============================] - 395s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00174\n",
      "Epoch 37/200\n",
      "372/372 [==============================] - 394s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00174\n",
      "Epoch 38/200\n",
      "372/372 [==============================] - 393s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00174\n",
      "Epoch 39/200\n",
      "372/372 [==============================] - 391s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00174\n",
      "Epoch 40/200\n",
      "372/372 [==============================] - 392s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00174\n",
      "Epoch 41/200\n",
      "372/372 [==============================] - 390s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00174\n",
      "Epoch 42/200\n",
      "372/372 [==============================] - 389s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00174\n",
      "Epoch 43/200\n",
      "372/372 [==============================] - 389s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0194\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00174\n",
      "Epoch 44/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00174\n",
      "Epoch 45/200\n",
      "372/372 [==============================] - 387s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00174\n",
      "Epoch 00045: early stopping\n",
      "Training time:  18816.93893623352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class BatchHistories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "batch_loss_fine = BatchHistories()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=20, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\"unet2_train_z40_grey_normal_lr.h5\", verbose=1, save_best_only=True),\n",
    "    batch_loss_fine\n",
    "]\n",
    "start = time.time()\n",
    "history_fine = model_pret.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model_done = keras.models.load_model('unet2_toy_train_z40_grey.h5', compile=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "def z_padding(input):\n",
    "    if input.shape[:2] == (512,512):\n",
    "        pass\n",
    "    else:\n",
    "        input=input[:512,:512,:]\n",
    "    z_size = 40-input.shape[2]%40\n",
    "    pad = np.zeros(input.shape[0:2]+ (z_size,))\n",
    "    return np.append(input, pad, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 512, 512, 40, 1)\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import ndpatch\n",
    "from scipy import ndimage\n",
    "test_img, header = nrrd.read('./test_data/R3.nrrd')\n",
    "im_deno = ndimage.median_filter(test_img, size=2)\n",
    "img_ad_eq = skimage.exposure.equalize_adapthist(im_deno, clip_limit=0.03)\n",
    "\n",
    "\n",
    "image_norm = (img_ad_eq - np.min(img_ad_eq))/(np.max(img_ad_eq)-np.min(img_ad_eq))\n",
    "patch_shape =(512, 512, 40)\n",
    "image_pad = z_padding(image_norm)\n",
    "test_patches=patchify.patchify(image_pad, (512,512,40), step=40)\n",
    "pat_size = test_patches.shape\n",
    "test_patches = test_patches.squeeze()\n",
    "test_patches = np.expand_dims(test_patches, -1)\n",
    "pred_patches = np.empty(shape=test_patches.shape)\n",
    "print(test_patches.shape)\n",
    "for i in np.arange(test_patches.shape[0]):\n",
    "    pred = model_pret.predict(np.expand_dims(test_patches[i,:,:,:,0],axis=0),batch_size=1, verbose=1)\n",
    "    pred = (pred > 0.05).astype(np.uint8)\n",
    "    pred = np.squeeze(pred)\n",
    "    pred_patches[i,:,:,:,0] =  pred\n",
    "#\n",
    "#predictions = model.predict(test_patches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 29, 512, 512, 40)\n"
     ]
    }
   ],
   "source": [
    "pred_patches=pred_patches.squeeze()\n",
    "pred_patches = np.expand_dims(np.expand_dims(pred_patches, axis=0),axis=0)\n",
    "print(pred_patches.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reconstruct image from patches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "reconstructed = patchify.unpatchify(pred_patches,image_pad.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Morphological operations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "recon_opened = ndimage.binary_opening(reconstructed, iterations=5).astype(int)\n",
    "recon_closed = ndimage.binary_closing(reconstructed, iterations=10).astype(int)\n",
    "recon_co = ndimage.binary_opening(recon_closed, iterations=5).astype(int)\n",
    "recon_oc = ndimage.binary_closing(recon_closed, iterations=10).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Connected components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def aorta_id(labels_out):\n",
    "\tlabels_out=labels_out.reshape((1,-1))\n",
    "\tlabels_out=labels_out[0,:]\n",
    "\tlabel=np.unique(labels_out)\n",
    "\thist, bin_edges=np.histogram(labels_out,bins=label)\n",
    "\thist=np.ndarray.tolist(hist)\n",
    "\thist_=hist\n",
    "\thist_=np.array(hist_)\n",
    "\thist.sort(reverse = True)\n",
    "\tidx=(hist_==hist[1])\n",
    "\tidx=idx+1-1\n",
    "\tidx_=np.sum(idx*label[0:len(idx)])\n",
    "\tprint('idx',idx_)\n",
    "\treturn idx_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import cc3d\n",
    "import nrrd\n",
    "import numpy as np\n",
    "labels_out, N = cc3d.connected_components(recon_oc, return_N=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 143\n"
     ]
    }
   ],
   "source": [
    "aorta_label = skull_id(labels_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "labels_big = labels_out * (labels_out == aorta_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "nrrd.write('R3_pred_z40_cc_t005_pretrained.seg.nrrd', labels_big)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "nrrd.write('R3_oc_pred_z40_cc_t005_pretrained.seg.nrrd', recon_oc)\n",
    "nrrd.write('R3_co_pred_z40_cc_t005_pretrained.seg.nrrd', recon_co)\n",
    "nrrd.write('R3_re_pred_z40_cc_t005_pretrained.seg.nrrd', reconstructed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pred = predict('toy_test', model)\n",
    "pred = np.squeeze(pred)\n",
    "#np.squeeze(pred)\n",
    "pred = (pred > 0.2).astype(np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "test_denoised = ndimage.median_filter(test, size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}