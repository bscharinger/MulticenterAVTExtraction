{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_tensorflow"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "colab": {
   "name": "main (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "gather": {
     "logged": 1635980540292
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "id": "vo77MIgCU3bW"
   },
   "source": [
    "from __future__ import division\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import nrrd\n",
    "import numpy as np\n",
    "\n",
    "import helper_funcs\n",
    "from data_gen import CTA\n",
    "from tensorflow.python.client import device_lib\n",
    "from Networks import model_unet_2\n",
    "from helper_funcs import dice_coef_loss"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ECBhMooU3bY",
    "outputId": "9e2cc2b4-34f9-4eca-9437-20698b5638a7"
   },
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "training_dir = \"./training_data/train_cyl_grey_im/\"\n",
    "label_dir = \"./training_data/train_cyl_grey_la/\"\n",
    "data_list =glob('{}/*.nrrd'.format(training_dir))\n",
    "label_list=glob('{}/*.nrrd'.format(label_dir))\n",
    "\n",
    "policy = keras.mixed_precision.Policy('mixed_float16')\n",
    "keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "img_size = (512, 512, 40)\n",
    "model = model_unet_2.get_model(img_size)\n",
    "a=model.summary(line_length=150)\n",
    "\n"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "(None, 512, 512, 40, 1)\n",
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                     Param #           Connected to                                      \n",
      "======================================================================================================================================================\n",
      "input_1 (InputLayer)                             [(None, 512, 512, 40, 1)]        0                                                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                                  (None, 512, 512, 40, 16)         448               input_1[0][0]                                     \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization (BatchNormalization)         (None, 512, 512, 40, 16)         64                conv3d[0][0]                                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation (Activation)                          (None, 512, 512, 40, 16)         0                 batch_normalization[0][0]                         \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)                                (None, 512, 512, 40, 16)         6928              activation[0][0]                                  \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNormalization)       (None, 512, 512, 40, 16)         64                conv3d_1[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_1 (Activation)                        (None, 512, 512, 40, 16)         0                 batch_normalization_1[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)                     (None, 256, 256, 20, 16)         0                 activation_1[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)                                (None, 256, 256, 20, 16)         6928              max_pooling3d[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNormalization)       (None, 256, 256, 20, 16)         64                conv3d_2[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_2 (Activation)                        (None, 256, 256, 20, 16)         0                 batch_normalization_2[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)                                (None, 256, 256, 20, 16)         6928              activation_2[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNormalization)       (None, 256, 256, 20, 16)         64                conv3d_3[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_3 (Activation)                        (None, 256, 256, 20, 16)         0                 batch_normalization_3[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)                   (None, 128, 128, 10, 16)         0                 activation_3[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)                                (None, 128, 128, 10, 16)         6928              max_pooling3d_1[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_4[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_4 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_4[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)                                (None, 128, 128, 10, 16)         6928              activation_4[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_5[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_5 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_5[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)                   (None, 64, 64, 5, 16)            0                 activation_5[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)                                (None, 64, 64, 5, 16)            6928              max_pooling3d_2[0][0]                             \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNormalization)       (None, 64, 64, 5, 16)            64                conv3d_6[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_6 (Activation)                        (None, 64, 64, 5, 16)            0                 batch_normalization_6[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)                                (None, 64, 64, 5, 16)            6928              activation_6[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNormalization)       (None, 64, 64, 5, 16)            64                conv3d_7[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_7 (Activation)                        (None, 64, 64, 5, 16)            0                 batch_normalization_7[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d (UpSampling3D)                     (None, 128, 128, 10, 16)         0                 activation_7[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate (Concatenate)                        (None, 128, 128, 10, 32)         0                 up_sampling3d[0][0]                               \n",
      "                                                                                                    activation_5[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)                                (None, 128, 128, 10, 16)         13840             concatenate[0][0]                                 \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_8[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_8 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_8[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)                                (None, 128, 128, 10, 16)         6928              activation_8[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNormalization)       (None, 128, 128, 10, 16)         64                conv3d_9[0][0]                                    \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_9 (Activation)                        (None, 128, 128, 10, 16)         0                 batch_normalization_9[0][0]                       \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)                   (None, 256, 256, 20, 16)         0                 activation_9[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)                      (None, 256, 256, 20, 32)         0                 up_sampling3d_1[0][0]                             \n",
      "                                                                                                    activation_3[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)                               (None, 256, 256, 20, 16)         13840             concatenate_1[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNormalization)      (None, 256, 256, 20, 16)         64                conv3d_10[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_10 (Activation)                       (None, 256, 256, 20, 16)         0                 batch_normalization_10[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)                               (None, 256, 256, 20, 16)         6928              activation_10[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNormalization)      (None, 256, 256, 20, 16)         64                conv3d_11[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_11 (Activation)                       (None, 256, 256, 20, 16)         0                 batch_normalization_11[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)                   (None, 512, 512, 40, 16)         0                 activation_11[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)                      (None, 512, 512, 40, 32)         0                 up_sampling3d_2[0][0]                             \n",
      "                                                                                                    activation_1[0][0]                                \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)                               (None, 512, 512, 40, 16)         13840             concatenate_2[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNormalization)      (None, 512, 512, 40, 16)         64                conv3d_12[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_12 (Activation)                       (None, 512, 512, 40, 16)         0                 batch_normalization_12[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)                               (None, 512, 512, 40, 16)         6928              activation_12[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNormalization)      (None, 512, 512, 40, 16)         64                conv3d_13[0][0]                                   \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_13 (Activation)                       (None, 512, 512, 40, 16)         0                 batch_normalization_13[0][0]                      \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)                               (None, 512, 512, 40, 1)          17                activation_13[0][0]                               \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "activation_14 (Activation)                       (None, 512, 512, 40, 1)          0                 conv3d_14[0][0]                                   \n",
      "======================================================================================================================================================\n",
      "Total params: 112,161\n",
      "Trainable params: 111,713\n",
      "Non-trainable params: 448\n",
      "______________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "gather": {
     "logged": 1633709498961
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true,
    "id": "UJWnfZpZU3bb"
   },
   "source": [
    "val_samples = int(np.floor(len(data_list)*0.2))\n",
    "random.Random(7331).shuffle(data_list)\n",
    "random.Random(7331).shuffle(label_list)\n",
    "\n",
    "train_img_paths = data_list[:-val_samples]\n",
    "train_lab_paths = label_list[:-val_samples]\n",
    "\n",
    "val_img_paths = data_list[-val_samples:]\n",
    "val_lab_paths = label_list[-val_samples:]\n",
    "\n",
    "train_gen = CTA(train_img_paths, train_lab_paths,1)\n",
    "valid_gen = CTA(val_img_paths, val_lab_paths,1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ],
   "metadata": {
    "id": "0zcH4AMACF9-"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FxFe6hDqU3bc",
    "outputId": "376caa2e-5f02-4a0f-dc64-f01c4ba267f8"
   },
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=[dice_coef_loss], metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "epochs = 200\n",
    "\n",
    "class BatchHistories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "batch_loss = BatchHistories()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\"unet2_toy_train_z40_grey.h5\", verbose=1, save_best_only=True),\n",
    "    batch_loss\n",
    "]\n",
    "start = time.time()\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "806/806 [==============================] - 1018s 1s/step - loss: 0.0517 - binary_crossentropy: 0.3114 - val_loss: 0.0180 - val_binary_crossentropy: 0.1759\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01799, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 2/200\n",
      "806/806 [==============================] - 929s 1s/step - loss: 0.0087 - binary_crossentropy: 0.0989 - val_loss: 0.0015 - val_binary_crossentropy: 0.0380\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01799 to 0.00148, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 3/200\n",
      "806/806 [==============================] - 926s 1s/step - loss: 8.8603e-04 - binary_crossentropy: 0.0286 - val_loss: 6.1031e-04 - val_binary_crossentropy: 0.0236\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00148 to 0.00061, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 4/200\n",
      "806/806 [==============================] - 917s 1s/step - loss: 4.5929e-04 - binary_crossentropy: 0.0201 - val_loss: 3.6143e-04 - val_binary_crossentropy: 0.0177\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00061 to 0.00036, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 5/200\n",
      "806/806 [==============================] - 919s 1s/step - loss: 2.9756e-04 - binary_crossentropy: 0.0157 - val_loss: 2.4403e-04 - val_binary_crossentropy: 0.0142\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00036 to 0.00024, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 6/200\n",
      "806/806 [==============================] - 936s 1s/step - loss: 2.1585e-04 - binary_crossentropy: 0.0131 - val_loss: 1.8539e-04 - val_binary_crossentropy: 0.0121\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00024 to 0.00019, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 7/200\n",
      "806/806 [==============================] - 923s 1s/step - loss: 1.6804e-04 - binary_crossentropy: 0.0112 - val_loss: 1.4564e-04 - val_binary_crossentropy: 0.0104\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00019 to 0.00015, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 8/200\n",
      "806/806 [==============================] - 936s 1s/step - loss: 1.3770e-04 - binary_crossentropy: 0.0099 - val_loss: 1.2105e-04 - val_binary_crossentropy: 0.0093\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00015 to 0.00012, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 9/200\n",
      "806/806 [==============================] - 946s 1s/step - loss: 1.1776e-04 - binary_crossentropy: 0.0089 - val_loss: 1.0498e-04 - val_binary_crossentropy: 0.0084\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00012 to 0.00010, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 10/200\n",
      "806/806 [==============================] - 933s 1s/step - loss: 1.0360e-04 - binary_crossentropy: 0.0082 - val_loss: 9.2181e-05 - val_binary_crossentropy: 0.0077\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00010 to 0.00009, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 11/200\n",
      "806/806 [==============================] - 931s 1s/step - loss: 9.3195e-05 - binary_crossentropy: 0.0076 - val_loss: 8.5040e-05 - val_binary_crossentropy: 0.0073\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00009 to 0.00009, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 12/200\n",
      "806/806 [==============================] - 1147s 1s/step - loss: 8.4996e-05 - binary_crossentropy: 0.0071 - val_loss: 7.7253e-05 - val_binary_crossentropy: 0.0068\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00009 to 0.00008, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 13/200\n",
      "806/806 [==============================] - 1521s 2s/step - loss: 7.8413e-05 - binary_crossentropy: 0.0067 - val_loss: 6.9975e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00008 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 14/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.5205e-05 - binary_crossentropy: 0.0065 - val_loss: 7.0057e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00007\n",
      "Epoch 15/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.4557e-05 - binary_crossentropy: 0.0064 - val_loss: 6.9587e-05 - val_binary_crossentropy: 0.0064\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 16/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.4087e-05 - binary_crossentropy: 0.0064 - val_loss: 6.9165e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 17/200\n",
      "806/806 [==============================] - 1541s 2s/step - loss: 7.3623e-05 - binary_crossentropy: 0.0064 - val_loss: 6.8748e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 18/200\n",
      "806/806 [==============================] - 1520s 2s/step - loss: 7.3153e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8202e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 19/200\n",
      "806/806 [==============================] - 1516s 2s/step - loss: 7.2897e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8222e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00007\n",
      "Epoch 20/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2872e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8237e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00007\n",
      "Epoch 21/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2826e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8113e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 22/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2795e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8170e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00007\n",
      "Epoch 23/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2773e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8118e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00007\n",
      "Epoch 24/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2763e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8190e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00007\n",
      "Epoch 25/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2763e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8110e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 26/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8181e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00007\n",
      "Epoch 27/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8105e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 28/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8070e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00007 to 0.00007, saving model to unet2_toy_train_z40_grey.h5\n",
      "Epoch 29/200\n",
      "806/806 [==============================] - 1557s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8116e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00007\n",
      "Epoch 30/200\n",
      "806/806 [==============================] - 1514s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8149e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00007\n",
      "Epoch 31/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8158e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00007\n",
      "Epoch 32/200\n",
      "806/806 [==============================] - 1537s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8214e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00007\n",
      "Epoch 33/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8165e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00007\n",
      "Epoch 34/200\n",
      "806/806 [==============================] - 1539s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8206e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00007\n",
      "Epoch 35/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8172e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00007\n",
      "Epoch 36/200\n",
      "806/806 [==============================] - 1536s 2s/step - loss: 7.2762e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8110e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00007\n",
      "Epoch 37/200\n",
      "806/806 [==============================] - 1538s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8187e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00007\n",
      "Epoch 38/200\n",
      "806/806 [==============================] - 1540s 2s/step - loss: 7.2761e-05 - binary_crossentropy: 0.0063 - val_loss: 6.8149e-05 - val_binary_crossentropy: 0.0063\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00007\n",
      "Epoch 00038: early stopping\n",
      "Training time:  51403.73484945297\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_pretrained_cyl_z40_new\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Model_pretrained_cyl_z40_new')\n",
    "model.save('Model_pretrained_cyl_z40_new.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Dice loss')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['val_loss'], label='Validation Dice Loss')\n",
    "plt.plot(history.history['loss'], label='Train Dice Loss')\n",
    "#plt.plot(batch_loss.losses)\n",
    "plt.legend()\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Dice loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "training_dir = \"./training_data/train_patch_z40_dnep_im\"\n",
    "label_dir = \"./training_data/train_patch_z40_dnep_la\"\n",
    "data_list =glob('{}/*.nrrd'.format(training_dir))\n",
    "label_list=glob('{}/*.nrrd'.format(label_dir))\n",
    "val_samples = int(np.floor(len(data_list)*0.2))\n",
    "random.Random(7331).shuffle(data_list)\n",
    "random.Random(7331).shuffle(label_list)\n",
    "\n",
    "train_img_paths = data_list[:-val_samples]\n",
    "train_lab_paths = label_list[:-val_samples]\n",
    "\n",
    "val_img_paths = data_list[-val_samples:]\n",
    "val_lab_paths = label_list[-val_samples:]\n",
    "\n",
    "train_gen = TOY(train_img_paths, train_lab_paths,1)\n",
    "valid_gen = TOY(val_img_paths, val_lab_paths,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model_pret = keras.models.load_model('unet2_toy_train_z40_grey.h5', compile=False)\n",
    "#for layer in model_pret.layers[:23]:\n",
    "\t#layer.trainable = False\n",
    "model_pret.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, epsilon=0.01), loss=[dice_coef_loss], metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "epochs = 200"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "372/372 [==============================] - 414s 1s/step - loss: 0.0025 - binary_crossentropy: 0.0313 - val_loss: 0.0019 - val_binary_crossentropy: 0.0267\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00195, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 2/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0020 - binary_crossentropy: 0.0272 - val_loss: 0.0019 - val_binary_crossentropy: 0.0249\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00195 to 0.00186, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 3/200\n",
      "372/372 [==============================] - 386s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0254 - val_loss: 0.0018 - val_binary_crossentropy: 0.0237\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00186 to 0.00182, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 4/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0242 - val_loss: 0.0018 - val_binary_crossentropy: 0.0226\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00182 to 0.00179, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 5/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0235 - val_loss: 0.0018 - val_binary_crossentropy: 0.0218\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00179 to 0.00178, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 6/200\n",
      "372/372 [==============================] - 387s 1s/step - loss: 0.0019 - binary_crossentropy: 0.0227 - val_loss: 0.0018 - val_binary_crossentropy: 0.0212\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00178 to 0.00176, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 7/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0221 - val_loss: 0.0018 - val_binary_crossentropy: 0.0209\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00176 to 0.00175, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 8/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0218 - val_loss: 0.0017 - val_binary_crossentropy: 0.0205\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00175 to 0.00175, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 9/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0214 - val_loss: 0.0017 - val_binary_crossentropy: 0.0201\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00175 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 10/200\n",
      "372/372 [==============================] - 392s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0211 - val_loss: 0.0017 - val_binary_crossentropy: 0.0199\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 11/200\n",
      "372/372 [==============================] - 379s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0208 - val_loss: 0.0017 - val_binary_crossentropy: 0.0198\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 12/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0206 - val_loss: 0.0018 - val_binary_crossentropy: 0.0196\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00174\n",
      "Epoch 13/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0203 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00174\n",
      "Epoch 14/200\n",
      "372/372 [==============================] - 380s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0202 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00174\n",
      "Epoch 15/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00174\n",
      "Epoch 16/200\n",
      "372/372 [==============================] - 487s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00174\n",
      "Epoch 17/200\n",
      "372/372 [==============================] - 585s 2s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00174\n",
      "Epoch 18/200\n",
      "372/372 [==============================] - 550s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00174\n",
      "Epoch 19/200\n",
      "372/372 [==============================] - 499s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00174\n",
      "Epoch 20/200\n",
      "372/372 [==============================] - 501s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0201 - val_loss: 0.0017 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00174\n",
      "Epoch 21/200\n",
      "372/372 [==============================] - 468s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00174\n",
      "Epoch 22/200\n",
      "372/372 [==============================] - 464s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00174\n",
      "Epoch 23/200\n",
      "372/372 [==============================] - 451s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00174\n",
      "Epoch 24/200\n",
      "372/372 [==============================] - 448s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00174\n",
      "Epoch 25/200\n",
      "372/372 [==============================] - 450s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00174 to 0.00174, saving model to unet2_train_z40_grey_normal_lr.h5\n",
      "Epoch 26/200\n",
      "372/372 [==============================] - 448s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00174\n",
      "Epoch 27/200\n",
      "372/372 [==============================] - 450s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00174\n",
      "Epoch 28/200\n",
      "372/372 [==============================] - 440s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00174\n",
      "Epoch 29/200\n",
      "372/372 [==============================] - 433s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00174\n",
      "Epoch 30/200\n",
      "372/372 [==============================] - 416s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00174\n",
      "Epoch 31/200\n",
      "372/372 [==============================] - 407s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00174\n",
      "Epoch 32/200\n",
      "372/372 [==============================] - 404s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00174\n",
      "Epoch 33/200\n",
      "372/372 [==============================] - 398s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00174\n",
      "Epoch 34/200\n",
      "372/372 [==============================] - 396s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00174\n",
      "Epoch 35/200\n",
      "372/372 [==============================] - 394s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00174\n",
      "Epoch 36/200\n",
      "372/372 [==============================] - 395s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0192\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00174\n",
      "Epoch 37/200\n",
      "372/372 [==============================] - 394s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00174\n",
      "Epoch 38/200\n",
      "372/372 [==============================] - 393s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00174\n",
      "Epoch 39/200\n",
      "372/372 [==============================] - 391s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00174\n",
      "Epoch 40/200\n",
      "372/372 [==============================] - 392s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00174\n",
      "Epoch 41/200\n",
      "372/372 [==============================] - 390s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00174\n",
      "Epoch 42/200\n",
      "372/372 [==============================] - 389s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00174\n",
      "Epoch 43/200\n",
      "372/372 [==============================] - 389s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0194\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00174\n",
      "Epoch 44/200\n",
      "372/372 [==============================] - 388s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0018 - val_binary_crossentropy: 0.0193\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00174\n",
      "Epoch 45/200\n",
      "372/372 [==============================] - 387s 1s/step - loss: 0.0018 - binary_crossentropy: 0.0200 - val_loss: 0.0017 - val_binary_crossentropy: 0.0191\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00174\n",
      "Epoch 00045: early stopping\n",
      "Training time:  18816.93893623352\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class BatchHistories(keras.callbacks.Callback):\n",
    "\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "batch_loss_fine = BatchHistories()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=20, verbose=1),\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(\"unet2_train_z40_grey_normal_lr.h5\", verbose=1, save_best_only=True),\n",
    "    batch_loss_fine\n",
    "]\n",
    "start = time.time()\n",
    "history_fine = model_pret.fit(train_gen, epochs=epochs, validation_data=valid_gen, callbacks=callbacks,shuffle=True)\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model_fertig = keras.models.load_model('unet2_toy_train_z40_grey.h5', compile=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 2070, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "#import ndpatch\n",
    "#model = keras.models.load_model('unet2_z32_bs1_ol0_good.h5', compile=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import skimage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import patchify\n",
    "def z_padding(input):\n",
    "    if input.shape[:2] == (512,512):\n",
    "        pass\n",
    "    else:\n",
    "        input=input[:512,:512,:]\n",
    "    z_size = 40-input.shape[2]%40\n",
    "    pad = np.zeros(input.shape[0:2]+ (z_size,))\n",
    "    return np.append(input, pad, axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 512, 512, 40, 1)\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "import ndpatch\n",
    "from scipy import ndimage\n",
    "test_img, header = nrrd.read('./test_data/R3.nrrd')\n",
    "im_deno = ndimage.median_filter(test_img, size=2)\n",
    "img_ad_eq = skimage.exposure.equalize_adapthist(im_deno, clip_limit=0.03)\n",
    "\n",
    "\n",
    "image_norm = (img_ad_eq - np.min(img_ad_eq))/(np.max(img_ad_eq)-np.min(img_ad_eq))\n",
    "patch_shape =(512, 512, 40)\n",
    "image_pad = z_padding(image_norm)\n",
    "test_patches=patchify.patchify(image_pad, (512,512,40), step=40)\n",
    "pat_size = test_patches.shape\n",
    "test_patches = test_patches.squeeze()\n",
    "test_patches = np.expand_dims(test_patches, -1)\n",
    "pred_patches = np.empty(shape=test_patches.shape)\n",
    "print(test_patches.shape)\n",
    "for i in np.arange(test_patches.shape[0]):\n",
    "    pred = model_pret.predict(np.expand_dims(test_patches[i,:,:,:,0],axis=0),batch_size=1, verbose=1)\n",
    "    pred = (pred > 0.05).astype(np.uint8)\n",
    "    pred = np.squeeze(pred)\n",
    "    pred_patches[i,:,:,:,0] =  pred\n",
    "#\n",
    "#predictions = model.predict(test_patches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 29, 512, 512, 40)\n"
     ]
    }
   ],
   "source": [
    "pred_patches=pred_patches.squeeze()\n",
    "pred_patches = np.expand_dims(np.expand_dims(pred_patches, axis=0),axis=0)\n",
    "print(pred_patches.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "reconstructed = patchify.unpatchify(pred_patches,image_pad.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(reconstructed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "recon_opened = ndimage.binary_opening(reconstructed, iterations=5).astype(int)\n",
    "recon_closed = ndimage.binary_closing(reconstructed, iterations=10).astype(int)\n",
    "recon_co = ndimage.binary_opening(recon_closed, iterations=5).astype(int)\n",
    "recon_oc = ndimage.binary_closing(recon_closed, iterations=10).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def skull_id(labels_out):\n",
    "\tlabels_out=labels_out.reshape((1,-1))\n",
    "\tlabels_out=labels_out[0,:]\n",
    "\tlabel=np.unique(labels_out)\n",
    "\thist, bin_edges=np.histogram(labels_out,bins=label)\n",
    "\thist=np.ndarray.tolist(hist)\n",
    "\thist_=hist\n",
    "\thist_=np.array(hist_)\n",
    "\thist.sort(reverse = True)\n",
    "\tidx=(hist_==hist[1])\n",
    "\tidx=idx+1-1\n",
    "\tidx_=np.sum(idx*label[0:len(idx)])\n",
    "\tprint('idx',idx_)\n",
    "\treturn idx_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import cc3d\n",
    "import nrrd\n",
    "import numpy as np\n",
    "labels_out, N = cc3d.connected_components(recon_oc, return_N=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 143\n"
     ]
    }
   ],
   "source": [
    "aorta_label = skull_id(labels_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "labels_big = labels_out * (labels_out == aorta_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#labels_big_op = ndimage.binary_opening(labels_big, iterations=2).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "nrrd.write('R3_pred_z40_cc_t005_pretrained.seg.nrrd', labels_big)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "nrrd.write('R3_oc_pred_z40_cc_t005_pretrained.seg.nrrd', recon_oc)\n",
    "nrrd.write('R3_co_pred_z40_cc_t005_pretrained.seg.nrrd', recon_co)\n",
    "nrrd.write('R3_re_pred_z40_cc_t005_pretrained.seg.nrrd', reconstructed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(reconstructed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def predict(test_dir, model):\n",
    "    test_list=glob('{}/*.nrrd'.format(test_dir))\n",
    "    image_list = []\n",
    "    i=0\n",
    "    for im in test_list:\n",
    "        ima, header = nrrd.read(test_list[i])\n",
    "        image_list.append(ima)\n",
    "    image_list = np.array(image_list)\n",
    "    predictions =  model.predict(image_list)\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pred = predict('toy_test', model)\n",
    "pred = np.squeeze(pred)\n",
    "#np.squeeze(pred)\n",
    "pred = (pred > 0.2).astype(np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.max(pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "\n",
    "filename = 'toy_test_97' + '.seg.nrrd'\n",
    "nrrd.write(filename, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jjXrYcjJU3bc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d6b0799a-71c0-4e15-ee88-ee5a14e7d028"
   },
   "source": [
    "\n",
    "#print(test_list)\n",
    "test_img1, hered = nrrd.read(test_list[0])\n",
    "a,b,c=test_img1.shape\n",
    "test_img1 = resizing(test_img1)\n",
    "test_img_1=np.expand_dims(test_img1,axis=3)\n",
    "test_img_1=np.expand_dims(test_img_1,axis=0)\n",
    "print(test_img_1.shape)\n",
    "print(a,b,c)"
   ],
   "execution_count": 41,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [41]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#print(test_list)\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m test_img1, hered \u001B[38;5;241m=\u001B[39m nrrd\u001B[38;5;241m.\u001B[39mread(\u001B[43mtest_list\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      3\u001B[0m a,b,c\u001B[38;5;241m=\u001B[39mtest_img1\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m      4\u001B[0m test_img1 \u001B[38;5;241m=\u001B[39m resizing(test_img1)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_list' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "_GLhR1QnyiTO",
    "outputId": "ac8978b6-f442-469b-ac2b-2f610f0855ad"
   },
   "source": [
    "test_pred1 = model.predict(test_img_1)\n",
    "pred_R1 = (test_pred1 > 0.2).astype(np.uint8)\n",
    "print(pred_R1.shape)\n",
    "pred=np.squeeze(pred_R1,axis=0)\n",
    "pred=np.squeeze(pred,axis=-1)"
   ],
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 256, 128, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min:  0.00042735042735042735 max: 0.9999389499389499\n",
      "1.0\n",
      "Pre-processing time:  142.01910758018494\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import skimage\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import nrrd\n",
    "import SimpleITK as sitk\n",
    "start = time.time()\n",
    "test, h = nrrd.read('./test/R1.nrrd')\n",
    "test = skimage.exposure.equalize_adapthist(test, clip_limit=0.03)\n",
    "test = ndimage.median_filter(test, size=2)\n",
    "\n",
    "print('min: ', np.min(test), 'max:', np.max(test))\n",
    "#test_vessel = skimage.filters.frangi(test)\n",
    "test_norm = (test - np.min(test))/(np.max(test)-np.min(test))\n",
    "print(np.max(test_norm))\n",
    "nrrd.write('test_denoised.nrrd', test_norm)\n",
    "end = time.time()\n",
    "print('Pre-processing time: ', end-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.136792404745481\n"
     ]
    }
   ],
   "source": [
    "sigma_est = skimage.restoration.estimate_sigma(test)\n",
    "print(sigma_est)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "test_denoised = ndimage.median_filter(test, size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([5.9341408e+07, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        5.6663110e+06, 3.8245950e+06, 2.7039820e+06, 1.6935380e+06,\n        1.3229800e+06, 1.6184710e+06, 2.0784540e+06, 2.4485500e+06,\n        2.5405410e+06, 2.3542690e+06, 1.9361680e+06, 1.6392870e+06,\n        1.2863100e+06, 9.9248600e+05, 7.6907900e+05, 5.7882600e+05,\n        4.8314700e+05, 3.9182400e+05, 3.2676600e+05, 2.7909600e+05,\n        2.3347300e+05, 2.1698000e+05, 1.9629500e+05, 1.7993000e+05,\n        1.6825800e+05, 1.5405000e+05, 1.5756700e+05, 1.6191400e+05,\n        1.8083100e+05, 2.3020100e+05, 3.2300500e+05, 5.6071200e+05,\n        1.0081810e+06, 1.8331140e+06, 3.2535680e+06, 5.4629750e+06,\n        7.9666790e+06, 1.1312746e+07, 1.3651708e+07, 1.4724064e+07,\n        1.4678042e+07, 1.3589977e+07, 1.3673371e+07, 1.3201631e+07,\n        1.2490068e+07, 1.1298419e+07, 9.2434880e+06, 7.7369650e+06,\n        5.8781080e+06, 4.3346030e+06, 3.1984930e+06, 2.3045120e+06,\n        1.8332550e+06, 1.3919440e+06, 1.0557260e+06, 7.9597900e+05,\n        6.0924100e+05, 4.6298800e+05, 4.0040000e+05, 3.4384000e+05,\n        3.0521000e+05, 2.7788500e+05, 2.4537500e+05, 2.3743700e+05,\n        2.2115700e+05, 2.0555600e+05, 1.9218300e+05, 1.7183200e+05,\n        1.6864000e+05, 1.5744700e+05, 1.4797800e+05, 1.3927500e+05,\n        1.2663100e+05, 1.2681700e+05, 1.2123600e+05, 1.1672100e+05,\n        1.1207700e+05, 1.0341200e+05, 1.0211500e+05, 9.6276000e+04,\n        8.7779000e+04, 8.0689000e+04, 7.2724000e+04, 6.3969000e+04,\n        5.9546000e+04, 5.4276000e+04, 4.8773000e+04, 4.3779000e+04,\n        3.6964000e+04, 3.3889000e+04, 2.9497000e+04, 2.4727000e+04,\n        2.0622000e+04, 1.6683000e+04, 1.3702000e+04, 1.0999000e+04,\n        8.9470000e+03, 7.1870000e+03, 5.7560000e+03, 4.8770000e+03,\n        3.9040000e+03, 3.2910000e+03, 2.5830000e+03, 2.1420000e+03,\n        1.6370000e+03, 1.3780000e+03, 1.1630000e+03, 1.0490000e+03,\n        9.3000000e+02, 7.7300000e+02, 8.1000000e+02, 7.2600000e+02,\n        7.4600000e+02, 7.2200000e+02, 6.6300000e+02, 6.6100000e+02,\n        7.0200000e+02, 6.0700000e+02, 6.1000000e+02, 5.7600000e+02,\n        6.1400000e+02, 5.5500000e+02, 5.4200000e+02, 5.9200000e+02,\n        5.1900000e+02, 5.0300000e+02, 5.2500000e+02, 4.5300000e+02,\n        5.0300000e+02, 4.5500000e+02, 4.2100000e+02, 4.4400000e+02,\n        4.6100000e+02, 3.9600000e+02, 3.6900000e+02, 3.6100000e+02,\n        3.9300000e+02, 3.8000000e+02, 3.7900000e+02, 3.5400000e+02,\n        3.2800000e+02, 3.4900000e+02, 3.0700000e+02, 2.9700000e+02,\n        3.0700000e+02, 2.5800000e+02, 2.8900000e+02, 2.8500000e+02,\n        2.5400000e+02, 2.4600000e+02, 2.6600000e+02, 2.4600000e+02,\n        2.4600000e+02, 2.3900000e+02, 2.2200000e+02, 2.0400000e+02,\n        1.8200000e+02, 2.1600000e+02, 2.0200000e+02, 1.7800000e+02,\n        1.8000000e+02, 1.7000000e+02, 1.3700000e+02, 1.5800000e+02,\n        1.6500000e+02, 1.3200000e+02, 1.3600000e+02, 1.0200000e+02,\n        1.1700000e+02, 1.0500000e+02, 1.1600000e+02, 5.6510000e+03]),\n array([0.        , 0.00390625, 0.0078125 , 0.01171875, 0.015625  ,\n        0.01953125, 0.0234375 , 0.02734375, 0.03125   , 0.03515625,\n        0.0390625 , 0.04296875, 0.046875  , 0.05078125, 0.0546875 ,\n        0.05859375, 0.0625    , 0.06640625, 0.0703125 , 0.07421875,\n        0.078125  , 0.08203125, 0.0859375 , 0.08984375, 0.09375   ,\n        0.09765625, 0.1015625 , 0.10546875, 0.109375  , 0.11328125,\n        0.1171875 , 0.12109375, 0.125     , 0.12890625, 0.1328125 ,\n        0.13671875, 0.140625  , 0.14453125, 0.1484375 , 0.15234375,\n        0.15625   , 0.16015625, 0.1640625 , 0.16796875, 0.171875  ,\n        0.17578125, 0.1796875 , 0.18359375, 0.1875    , 0.19140625,\n        0.1953125 , 0.19921875, 0.203125  , 0.20703125, 0.2109375 ,\n        0.21484375, 0.21875   , 0.22265625, 0.2265625 , 0.23046875,\n        0.234375  , 0.23828125, 0.2421875 , 0.24609375, 0.25      ,\n        0.25390625, 0.2578125 , 0.26171875, 0.265625  , 0.26953125,\n        0.2734375 , 0.27734375, 0.28125   , 0.28515625, 0.2890625 ,\n        0.29296875, 0.296875  , 0.30078125, 0.3046875 , 0.30859375,\n        0.3125    , 0.31640625, 0.3203125 , 0.32421875, 0.328125  ,\n        0.33203125, 0.3359375 , 0.33984375, 0.34375   , 0.34765625,\n        0.3515625 , 0.35546875, 0.359375  , 0.36328125, 0.3671875 ,\n        0.37109375, 0.375     , 0.37890625, 0.3828125 , 0.38671875,\n        0.390625  , 0.39453125, 0.3984375 , 0.40234375, 0.40625   ,\n        0.41015625, 0.4140625 , 0.41796875, 0.421875  , 0.42578125,\n        0.4296875 , 0.43359375, 0.4375    , 0.44140625, 0.4453125 ,\n        0.44921875, 0.453125  , 0.45703125, 0.4609375 , 0.46484375,\n        0.46875   , 0.47265625, 0.4765625 , 0.48046875, 0.484375  ,\n        0.48828125, 0.4921875 , 0.49609375, 0.5       , 0.50390625,\n        0.5078125 , 0.51171875, 0.515625  , 0.51953125, 0.5234375 ,\n        0.52734375, 0.53125   , 0.53515625, 0.5390625 , 0.54296875,\n        0.546875  , 0.55078125, 0.5546875 , 0.55859375, 0.5625    ,\n        0.56640625, 0.5703125 , 0.57421875, 0.578125  , 0.58203125,\n        0.5859375 , 0.58984375, 0.59375   , 0.59765625, 0.6015625 ,\n        0.60546875, 0.609375  , 0.61328125, 0.6171875 , 0.62109375,\n        0.625     , 0.62890625, 0.6328125 , 0.63671875, 0.640625  ,\n        0.64453125, 0.6484375 , 0.65234375, 0.65625   , 0.66015625,\n        0.6640625 , 0.66796875, 0.671875  , 0.67578125, 0.6796875 ,\n        0.68359375, 0.6875    , 0.69140625, 0.6953125 , 0.69921875,\n        0.703125  , 0.70703125, 0.7109375 , 0.71484375, 0.71875   ,\n        0.72265625, 0.7265625 , 0.73046875, 0.734375  , 0.73828125,\n        0.7421875 , 0.74609375, 0.75      , 0.75390625, 0.7578125 ,\n        0.76171875, 0.765625  , 0.76953125, 0.7734375 , 0.77734375,\n        0.78125   , 0.78515625, 0.7890625 , 0.79296875, 0.796875  ,\n        0.80078125, 0.8046875 , 0.80859375, 0.8125    , 0.81640625,\n        0.8203125 , 0.82421875, 0.828125  , 0.83203125, 0.8359375 ,\n        0.83984375, 0.84375   , 0.84765625, 0.8515625 , 0.85546875,\n        0.859375  , 0.86328125, 0.8671875 , 0.87109375, 0.875     ,\n        0.87890625, 0.8828125 , 0.88671875, 0.890625  , 0.89453125,\n        0.8984375 , 0.90234375, 0.90625   , 0.91015625, 0.9140625 ,\n        0.91796875, 0.921875  , 0.92578125, 0.9296875 , 0.93359375,\n        0.9375    , 0.94140625, 0.9453125 , 0.94921875, 0.953125  ,\n        0.95703125, 0.9609375 , 0.96484375, 0.96875   , 0.97265625,\n        0.9765625 , 0.98046875, 0.984375  , 0.98828125, 0.9921875 ,\n        0.99609375, 1.        ]),\n <BarContainer object of 256 artists>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_norm.ravel(), bins=256, range=(0.0, 1.0), fc='k', ec='k')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([59341408.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,        0.,        0.,        0.,        0.,\n               0.,        0.,  2546313.,  1764742.,  2135857.,  2029353.,\n         1808573.,  1449024.,  1106072.,   867938.,   754981.,   748553.,\n          824295.,   948623.,  1090798.,  1222767.,  1425747.,  1378017.,\n         1377885.,  1333856.,  1254250.,  1153966.,  1042756.,   926519.,\n          815662.,   713943.,   622215.,   539088.,   469071.,   438322.,\n          353883.,   310778.,   274508.,   244196.,   218091.,   196061.,\n          179106.,   163564.,   150441.,   139605.,   129545.,   130772.,\n          113944.,   108013.,   103004.,    98014.,    94632.,    90994.,\n           88632.,    86720.,    85744.,    85207.,    86580.,    89023.,\n          102076.,   105178.,   121245.,   146969.,   184002.,   241822.,\n          326773.,   447899.,   619870.,   858143.,  1182236.,  1613557.,\n         2168585.,  3110109.,  3738685.,  4641928.,  5567129.,  6422623.,\n         7136581.,  7641813.,  7944328.,  8028924.,  7982571.,  7842937.,\n         7684507.,  7521963.,  7939098.,  7234091.,  7088067.,  6881379.,\n         6603465.,  6247289.,  5785178.,  5271200.,  4701805.,  4125612.,\n         3558906.,  3045627.,  2578879.,  2335387.,  1828054.,  1554388.,\n         1331074.,  1142301.,   985455.,   848405.,   732221.,   630958.,\n          539876.,   463571.,   399136.,  5935690.]),\n array([0.        , 0.00390625, 0.0078125 , 0.01171875, 0.015625  ,\n        0.01953125, 0.0234375 , 0.02734375, 0.03125   , 0.03515625,\n        0.0390625 , 0.04296875, 0.046875  , 0.05078125, 0.0546875 ,\n        0.05859375, 0.0625    , 0.06640625, 0.0703125 , 0.07421875,\n        0.078125  , 0.08203125, 0.0859375 , 0.08984375, 0.09375   ,\n        0.09765625, 0.1015625 , 0.10546875, 0.109375  , 0.11328125,\n        0.1171875 , 0.12109375, 0.125     , 0.12890625, 0.1328125 ,\n        0.13671875, 0.140625  , 0.14453125, 0.1484375 , 0.15234375,\n        0.15625   , 0.16015625, 0.1640625 , 0.16796875, 0.171875  ,\n        0.17578125, 0.1796875 , 0.18359375, 0.1875    , 0.19140625,\n        0.1953125 , 0.19921875, 0.203125  , 0.20703125, 0.2109375 ,\n        0.21484375, 0.21875   , 0.22265625, 0.2265625 , 0.23046875,\n        0.234375  , 0.23828125, 0.2421875 , 0.24609375, 0.25      ,\n        0.25390625, 0.2578125 , 0.26171875, 0.265625  , 0.26953125,\n        0.2734375 , 0.27734375, 0.28125   , 0.28515625, 0.2890625 ,\n        0.29296875, 0.296875  , 0.30078125, 0.3046875 , 0.30859375,\n        0.3125    , 0.31640625, 0.3203125 , 0.32421875, 0.328125  ,\n        0.33203125, 0.3359375 , 0.33984375, 0.34375   , 0.34765625,\n        0.3515625 , 0.35546875, 0.359375  , 0.36328125, 0.3671875 ,\n        0.37109375, 0.375     , 0.37890625, 0.3828125 , 0.38671875,\n        0.390625  , 0.39453125, 0.3984375 , 0.40234375, 0.40625   ,\n        0.41015625, 0.4140625 , 0.41796875, 0.421875  , 0.42578125,\n        0.4296875 , 0.43359375, 0.4375    , 0.44140625, 0.4453125 ,\n        0.44921875, 0.453125  , 0.45703125, 0.4609375 , 0.46484375,\n        0.46875   , 0.47265625, 0.4765625 , 0.48046875, 0.484375  ,\n        0.48828125, 0.4921875 , 0.49609375, 0.5       , 0.50390625,\n        0.5078125 , 0.51171875, 0.515625  , 0.51953125, 0.5234375 ,\n        0.52734375, 0.53125   , 0.53515625, 0.5390625 , 0.54296875,\n        0.546875  , 0.55078125, 0.5546875 , 0.55859375, 0.5625    ,\n        0.56640625, 0.5703125 , 0.57421875, 0.578125  , 0.58203125,\n        0.5859375 , 0.58984375, 0.59375   , 0.59765625, 0.6015625 ,\n        0.60546875, 0.609375  , 0.61328125, 0.6171875 , 0.62109375,\n        0.625     , 0.62890625, 0.6328125 , 0.63671875, 0.640625  ,\n        0.64453125, 0.6484375 , 0.65234375, 0.65625   , 0.66015625,\n        0.6640625 , 0.66796875, 0.671875  , 0.67578125, 0.6796875 ,\n        0.68359375, 0.6875    , 0.69140625, 0.6953125 , 0.69921875,\n        0.703125  , 0.70703125, 0.7109375 , 0.71484375, 0.71875   ,\n        0.72265625, 0.7265625 , 0.73046875, 0.734375  , 0.73828125,\n        0.7421875 , 0.74609375, 0.75      , 0.75390625, 0.7578125 ,\n        0.76171875, 0.765625  , 0.76953125, 0.7734375 , 0.77734375,\n        0.78125   , 0.78515625, 0.7890625 , 0.79296875, 0.796875  ,\n        0.80078125, 0.8046875 , 0.80859375, 0.8125    , 0.81640625,\n        0.8203125 , 0.82421875, 0.828125  , 0.83203125, 0.8359375 ,\n        0.83984375, 0.84375   , 0.84765625, 0.8515625 , 0.85546875,\n        0.859375  , 0.86328125, 0.8671875 , 0.87109375, 0.875     ,\n        0.87890625, 0.8828125 , 0.88671875, 0.890625  , 0.89453125,\n        0.8984375 , 0.90234375, 0.90625   , 0.91015625, 0.9140625 ,\n        0.91796875, 0.921875  , 0.92578125, 0.9296875 , 0.93359375,\n        0.9375    , 0.94140625, 0.9453125 , 0.94921875, 0.953125  ,\n        0.95703125, 0.9609375 , 0.96484375, 0.96875   , 0.97265625,\n        0.9765625 , 0.98046875, 0.984375  , 0.98828125, 0.9921875 ,\n        0.99609375, 1.        ]),\n <BarContainer object of 256 artists>)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import skimage\n",
    "p2, p98 = np.percentile(test_norm, (2, 98))\n",
    "img_contrast_streched = skimage.exposure.rescale_intensity(test_norm, in_range=(p2, p98))\n",
    "plt.hist(img_contrast_streched.ravel(), bins=256, range=(0.0, 1.0), fc='k', ec='k')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "nrrd.write('test_contrast_streched.nrrd', img_contrast_streched)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_eq = skimage.exposure.equalize_hist(test_norm)\n",
    "plt.hist(img_eq.ravel(), bins=256, range=(0.0, 1.0), fc='k', ec='k')\n",
    "nrrd.write('test_equalized.nrrd', img_eq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_ad_eq = skimage.exposure.equalize_adapthist(test_norm, clip_limit=0.03)\n",
    "plt.hist(img_ad_eq.ravel(), bins=256, range=(0.0, 1.0), fc='k', ec='k')\n",
    "nrrd.write('test_ad_equalized.nrrd', img_ad_eq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "r1, h = nrrd.read('./Rider/Rider/R1 (AD)/R1.seg.nrrd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "nrrd.write('R1_label.nrrd',r1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Input \u001B[1;32mIn [85]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m r1_label_orig \u001B[38;5;241m=\u001B[39m z_padding(r1_label_orig)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muint32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m r1_label_test, h \u001B[38;5;241m=\u001B[39mnrrd\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./labels_big.seg.nrrd\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m dice_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[43mhelper_funcs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdice_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr1_label_orig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr1_label_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDice score: \u001B[39m\u001B[38;5;124m'\u001B[39m, dice_score)\n",
      "File \u001B[1;32mE:\\Uni\\Thesis\\helper_funcs.py:33\u001B[0m, in \u001B[0;36mdice_loss\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     31\u001B[0m y_true \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mcast(y_true, tf\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     32\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39msigmoid(tf\u001B[38;5;241m.\u001B[39mcast(y_pred, tf\u001B[38;5;241m.\u001B[39mfloat32))\n\u001B[1;32m---> 33\u001B[0m numerator \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum(\u001B[43my_true\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m)\n\u001B[0;32m     34\u001B[0m denominator \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mreduce_sum(y_true \u001B[38;5;241m+\u001B[39m y_pred)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m numerator \u001B[38;5;241m/\u001B[39m denominator\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367\u001B[0m, in \u001B[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m   1362\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1363\u001B[0m   \u001B[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001B[39;00m\n\u001B[0;32m   1364\u001B[0m   \u001B[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001B[39;00m\n\u001B[0;32m   1365\u001B[0m   \u001B[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001B[39;00m\n\u001B[0;32m   1366\u001B[0m   x, y \u001B[38;5;241m=\u001B[39m maybe_promote_tensors(x, y, force_same_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m-> 1367\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1368\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1369\u001B[0m   \u001B[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001B[39;00m\n\u001B[0;32m   1370\u001B[0m   \u001B[38;5;66;03m# object that can implement the operator with knowledge of itself\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1373\u001B[0m   \u001B[38;5;66;03m# original error from the LHS, because it may be more\u001B[39;00m\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;66;03m# informative.\u001B[39;00m\n\u001B[0;32m   1375\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(y), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__r\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m op_name):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1710\u001B[0m, in \u001B[0;36m_mul_dispatch\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   1708\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m sparse_tensor\u001B[38;5;241m.\u001B[39mSparseTensor(y\u001B[38;5;241m.\u001B[39mindices, new_vals, y\u001B[38;5;241m.\u001B[39mdense_shape)\n\u001B[0;32m   1709\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1710\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmultiply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 206\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m    208\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[0;32m    209\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[0;32m    210\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530\u001B[0m, in \u001B[0;36mmultiply\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmath.multiply\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    483\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmultiply\u001B[39m(x, y, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    485\u001B[0m   \u001B[38;5;124;03m\"\"\"Returns an element-wise x * y.\u001B[39;00m\n\u001B[0;32m    486\u001B[0m \n\u001B[0;32m    487\u001B[0m \u001B[38;5;124;03m  For example:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    527\u001B[0m \u001B[38;5;124;03m   * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\u001B[39;00m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m--> 530\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_math_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6235\u001B[0m, in \u001B[0;36mmul\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   6233\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   6234\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 6235\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6236\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[0;32m   6237\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   6939\u001B[0m message \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6940\u001B[0m \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m-> 6941\u001B[0m \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_status_to_exception\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[1;34m(value, from_value)\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: required broadcastable shapes [Op:Mul]"
     ]
    }
   ],
   "source": [
    "r1_label_orig, h = nrrd.read('./Rider/Rider/R3/R3.seg.nrrd')\n",
    "r1_label_orig = z_padding(r1_label_orig).astype('uint32')\n",
    "r1_label_test, h =nrrd.read('./labels_big.seg.nrrd')\n",
    "dice_score = 1 - helper_funcs.dice_loss(r1_label_orig, r1_label_test)\n",
    "print('Dice score: ', dice_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint32\n"
     ]
    }
   ],
   "source": [
    "print(r1_label_orig.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "nrrd.write('R1_label_orig.seg.nrrd',r1_label_orig)\n",
    "nrrd.write('R1_label_test.seg.nrrd',r1_label_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}